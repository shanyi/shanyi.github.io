---
layout: article
title: "Notes: Learning statistics with R: A tutorial for psychology students and other beginners"
categories: essays
---

### CH1: Why do we learn statistics

- keep personal biases under control—belief bias effect
- truth is sometimes hidden—Simpson’s paradox (male vs female admitted rate)
- still, statistics is just a tool but not substitute for careful thought

> why so important for psychology?

- the study about human is more complicated than physics; more reliant on statistics
- stats deeply intertwined with research design
- understand others’ works as stats are used widely in official literature
- expensive asking others to do—government payments to university—stats is national priority
- survival tool for 21st century

### CH2: A brief introduction to research design

- psychological measurement—clear or tricky?
- operationalisation: define measurement
	- a theoretical construct—e.g. age
	- a measure—e.g. a question in a survey about age
	- an operationalisation—connection between the two above
	- a variable—the result from the above, data
- scales of measurement
	- nominal scale (categorical scale)
	- ordinal scale
	- interval scale—no natural zero value—e.g. temparature
	- ratio scale—natural zero value—e.g. response time—0 is no time at all
	- continuous variable has sth in the middle—e.g. interval & ratio
	- discrete variable has nothing in the middle—all of the above could be possible discrete variable
	- likert scales—maybe quasi-interval variable in practice
- reliability of a measurement—how precisely measuring sth—repeatability/consistency of the measurement
	- test-retest reliability
	- inter-rater reliability—across people; e.g. someone else rates my intelligence
	- parallel forms reliability—across theoretical-equivalent measurements
	- internal consistency reliability—similar answers from individual parts in a measurement
- role of the variable
	- to be explained—dependent variable—outcome
	- to do the explaining—independent variable—predictor
- research
	- experimental research—randomisation—full control
	- non-experimental research
	- quasi-experimental research—who smoke vs. who don’t smoke
	- case study—detailed description
- validity—how accurate measuring sth
	- internal validity—the convincing causal relationships between IV and DV inside the study
	- external validity—generalisability in real life
	- construct validity—whether measuring the thing I want to measure
	face validity—a measure looks like what it is doing or not
	- ecological validity—study set up approximate the real world scenario—similar to face validity, not guarantee external validity
- confounds, artifacts, and other threats to validity
	- confound—additional influencing factor—more concerned by non-experimental research
	- artifact—special and uniquely happened in the study—low external validity—more concerned by experimental research
	- history effects—things occur during the study itself influence the outcomes, e.g. sth happen between pre- and post-test
	- maturational effects
	- selection bias—e.g. too many female in one group
	- differential attrition—e.g. people drop out in the middle, staying ones are more patient/tolerant/…
		- homogeneous attrition—similar drop out every group—loss external validity
		- heterogeneous attrition—different across groups—loss both internal and external validity
	- non-response bias—people response to a survey may be systematically different from others who don’t/data missing systematically
	- regression to the mean
	- experimenter bias—double blind design
	- demand effects and reactivity
	- placebo effect
	- situation, measurement, and subpopulation effects
	- fraud, deception, and self-deception
	​